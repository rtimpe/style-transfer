{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implementation of [universal style transfer via feature transforms by Li et al](https://arxiv.org/pdf/1705.08086.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make variables display whenever they are on their own line (not just the last line of a cell)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio import imread\n",
    "import skimage.transform\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer = 'conv4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featureize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_features('D:/test2017', out_layer_name='vgg_19/' + layer + '/' + layer + '_1', num_images=40000)\n",
    "compute_features('D:/val2017', out_layer_name='vgg_19/' + layer + '/' + layer + '_1', num_images=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_to_sizes = {\n",
    "    'conv1': (None, 224, 224, 64),\n",
    "    'conv2': (None, 112, 112, 128),\n",
    "    'conv4': (None, 28, 28, 512)\n",
    "}\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "images_ph = tf.placeholder('float', (None, 224, 224, 3), name='images')\n",
    "features_ph = tf.placeholder('float', layer_to_sizes[layer], name='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dataset = make_precomputed_dataset('D:/test2017', layer, num_images=40000, batch_size=32)\n",
    "val_dataset = make_precomputed_dataset('D:/val2017', layer, num_images=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "architecture_4 = [(3, 256), 'upsample', (3, 256), (3, 256), (3, 256), (3, 128), 'upsample', (3, 112), (3, 64), 'upsample', (3, 64), (3, 3)]\n",
    "architecture_1 = [(3, 3)]\n",
    "reconstructed_image, regularized = make_decoder(features_ph, architecture_4, sess)\n",
    "(per_img_loss, total_loss) = create_loss(images_ph, features_ph, \n",
    "                                         reconstructed_image, 'vgg_19/' + layer + '/' + layer + '_1', \n",
    "                                         regularized, sess, lambda_reg=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(train_step, merged) = setup_training(total_loss, train_dataset, sess, lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(per_img_loss, train_step, merged, train_dataset, val_dataset, images_ph, features_ph, sess,\n",
    "      num_epochs=1, summary_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'decoder'))\n",
    "saver.save(sess, './decoder4/decoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "saver = tf.train.import_meta_graph('decoder4/decoder.meta')\n",
    "writer = tf.summary.FileWriter('summaries', sess.graph)\n",
    "saver.restore(sess, tf.train.latest_checkpoint('decoder4/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reconstructed_image = sess.graph.get_tensor_by_name('decoder/conv_layer_11/Relu:0')\n",
    "features_ph = sess.graph.get_tensor_by_name('features:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('C:/users/rtimpe/downloads/cat.jpg')\n",
    "img = skimage.transform.resize(img, (224, 224, 3))\n",
    "img *= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_img = encode_image(img[np.newaxis, :,:,:], 'vgg_19/' + layer + '/' + layer + '_1')\n",
    "reconstructed = sess.run(reconstructed_image, feed_dict={features_ph: encoded_img})\n",
    "reconstructed = np.squeeze(reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((reconstructed).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## style transfer stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = encode_file('C:/users/rtimpe/downloads/face.jpg', layer)\n",
    "style = encode_file('C:/users/rtimpe/downloads/lights.jpg', layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first whiten\n",
    "v = np.transpose(content, (3, 0, 1, 2)).reshape(content.shape[-1], -1)\n",
    "v_centered = v - np.mean(v, axis=1)[:, np.newaxis]\n",
    "w, _ = whiten(v_centered)\n",
    "\n",
    "# now color\n",
    "style_r = np.transpose(style, (3, 0, 1, 2)).reshape(style.shape[-1], -1)\n",
    "style_centered = style_r - np.mean(style_r, axis=1)[:, np.newaxis]\n",
    "cs, _ = color(w, style_centered)\n",
    "cs = cs + style_r.mean(axis=1)[:, np.newaxis]\n",
    "cs_r = np.reshape(cs, (1, 28, 28, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(np.dot(w, w.T) / 783 - np.eye(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(np.dot(cs, cs.T) / 783 - np.dot(style_centered, style_centered.T) / 783)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = .4\n",
    "interp = alpha * content + (1.0 - alpha) * cs_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reconstructed = sess.run(reconstructed_image, feed_dict={features_ph: interp})\n",
    "reconstructed = np.squeeze(reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(figsize=(15, 15))\n",
    "ax.imshow(skimage.transform.resize(reconstructed.astype(np.uint8), (600, 600, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other crap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = encode_file('C:/users/rtimpe/downloads/cat.jpg', layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = content.reshape(-1, content.shape[-1]).T\n",
    "v_centered = v - np.mean(v, axis=1)[:, np.newaxis]\n",
    "w, _ = whiten(v_centered)\n",
    "w = w + np.mean(v, axis=1)[:, np.newaxis]\n",
    "w = np.reshape(w, (1, 28, 28, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = .15\n",
    "interp = alpha * content + (1.0 - alpha) * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reconstructed = sess.run(reconstructed_image, feed_dict={features_ph: interp})\n",
    "reconstructed = np.squeeze(reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(figsize=(15, 15))\n",
    "ax.imshow(skimage.transform.resize(reconstructed.astype(np.uint8), (600, 600, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = np.array([[1,2], [2,4]])\n",
    "c2 = np.eye(2)\n",
    "mu = np.array([0, 0])\n",
    "x = np.random.multivariate_normal(mu, c1, 500).T \n",
    "x -= x.mean(axis=1)[:,np.newaxis] # colored\n",
    "y = np.random.multivariate_normal(mu, c2, 600).T\n",
    "y -= y.mean(axis=1)[:,np.newaxis] # whitened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, _ = whiten(y)\n",
    "c, _ = color(w, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(c, c.T) / 599"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(w, w.T) / 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
